{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, I decided to try the DQN method on the same \"taxi-v3\", through the policy based method suing Boltzmann policy for the rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "     -------------------------------------- 721.7/721.7 kB 4.2 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting importlib-metadata>=4.8.0\n",
      "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
      "Collecting gym-notices>=0.0.4\n",
      "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from gym) (1.21.5)\n",
      "Collecting cloudpickle>=1.2.0\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.8.0->gym) (4.4.0)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml): started\n",
      "  Building wheel for gym (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827629 sha256=7ada41539e996d37e9561e01893695a8fa19390992236d3acf817a5092ab3898\n",
      "  Stored in directory: c:\\users\\kushi arun kumar\\appdata\\local\\pip\\cache\\wheels\\e0\\d1\\88\\c3c712101dac979e0bf77cdd9c89bc650ad5f41c48d8d6f167\n",
      "Successfully built gym\n",
      "Installing collected packages: gym-notices, zipp, cloudpickle, importlib-metadata, gym\n",
      "Successfully installed cloudpickle-2.2.1 gym-0.26.2 gym-notices-0.0.8 importlib-metadata-6.7.0 zipp-3.15.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow==2.4.1\n",
      "  Downloading tensorflow-2.4.1-cp37-cp37m-win_amd64.whl (370.7 MB)\n",
      "     -------------------------------------- 370.7/370.7 MB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow==2.4.1) (0.38.4)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 10.5 MB/s eta 0:00:00\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     -------------------------------------- 132.0/132.0 kB 8.1 MB/s eta 0:00:00\n",
      "Collecting tensorboard~=2.4\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ---------------------------------------- 6.0/6.0 MB 9.8 MB/s eta 0:00:00\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-win_amd64.whl (13.2 MB)\n",
      "     ---------------------------------------- 13.2/13.2 MB 7.6 MB/s eta 0:00:00\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-4.24.4-cp37-cp37m-win_amd64.whl (430 kB)\n",
      "     -------------------------------------- 430.0/430.0 kB 8.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "     -------------------------------------- 462.0/462.0 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp37-cp37m-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 6.4 MB/s eta 0:00:00\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB ? eta 0:00:00\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (65.6.3)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "     ---------------------------------------- 94.2/94.2 kB 5.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.28.1)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.3-py3-none-any.whl (233 kB)\n",
      "     ------------------------------------- 233.6/233.6 kB 14.0 MB/s eta 0:00:00\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.32.0-py2.py3-none-any.whl (195 kB)\n",
      "     ------------------------------------- 195.5/195.5 kB 12.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ------------------------------------- 781.3/781.3 kB 12.4 MB/s eta 0:00:00\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.20.3-cp37-cp37m-win_amd64.whl (905 kB)\n",
      "     ------------------------------------- 905.1/905.1 kB 11.3 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.4.0-py3-none-any.whl (9.5 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ------------------------------------- 181.3/181.3 kB 10.7 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (6.7.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2024.7.4)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Downloading MarkupSafe-2.1.5-cp37-cp37m-win_amd64.whl (17 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.15.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "     ---------------------------------------- 84.9/84.9 kB ? eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ---------------------------------------- 151.7/151.7 kB ? eta 0:00:00\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4855 sha256=b2fca12691f81f63020f2e6b522bf0b47077e421c013a970055d66c7ba409061\n",
      "  Stored in directory: c:\\users\\kushi arun kumar\\appdata\\local\\pip\\cache\\wheels\\19\\b5\\5e\\dde0eb16713e5c2e7d5fc48df6c6d70cc85a7d665a7cdc399e\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19597 sha256=407cc1c8ab0d287a2c9e16b1a751a6a7dbab5312ce58bf9c681d99673e077736\n",
      "  Stored in directory: c:\\users\\kushi arun kumar\\appdata\\local\\pip\\cache\\wheels\\70\\32\\b7\\c7efd67541df013b25b28029490a3d406b617e429923a26c72\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard-plugin-wit, flatbuffers, tensorboard-data-server, six, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, gast, cachetools, werkzeug, rsa, requests-oauthlib, pyasn1-modules, opt-einsum, markdown, keras-preprocessing, h5py, grpcio, google-pasta, astunparse, absl-py, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.4.0\n",
      "    Uninstalling typing_extensions-4.4.0:\n",
      "      Successfully uninstalled typing_extensions-4.4.0\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.5\n",
      "    Uninstalling numpy-1.21.5:\n",
      "      Successfully uninstalled numpy-1.21.5\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-0.15.0 astunparse-1.6.3 cachetools-5.4.0 flatbuffers-1.12 gast-0.3.3 google-auth-2.32.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.32.0 h5py-2.10.0 keras-preprocessing-1.1.2 markdown-3.4.4 numpy-1.19.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.20.3 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-2.0.0 rsa-4.9 six-1.15.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.4.1 tensorflow-estimator-2.4.0 termcolor-1.1.0 typing-extensions-3.7.4.3 werkzeug-2.2.3 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting keras-rl2\n",
      "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
      "     -------------------------------------- 52.1/52.1 kB 243.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from keras-rl2) (2.4.1)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (3.20.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.19.5)\n",
      "Requirement already satisfied: grpcio~=1.32.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.32.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (0.2.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.15.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.12.1)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (0.38.4)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.12)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.1.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (2.4.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (3.7.4.3)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.6.3)\n",
      "Requirement already satisfied: h5py~=2.10.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (2.10.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (0.15.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (2.11.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (1.1.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorflow->keras-rl2) (0.3.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (2.28.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (3.4.4)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (2.2.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (2.32.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (1.8.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (65.6.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tensorboard~=2.4->tensorflow->keras-rl2) (0.4.6)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow->keras-rl2) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow->keras-rl2) (4.9)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow->keras-rl2) (5.4.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras-rl2) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow->keras-rl2) (6.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-rl2) (2024.7.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-rl2) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-rl2) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow->keras-rl2) (1.26.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.4->tensorflow->keras-rl2) (2.1.5)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.4->tensorflow->keras-rl2) (3.15.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow->keras-rl2) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow->keras-rl2) (3.2.2)\n",
      "Installing collected packages: keras-rl2\n",
      "Successfully installed keras-rl2-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gym\n",
    "%pip install tensorflow==2.4.1\n",
    "%pip install keras-rl2\n",
    "#installing gymnasium, tensorflow and keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "\n",
    "#importing necessary libraries and modules - here there is, numpy for numerical calculations, gym to create the environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name=\"Taxi-v3\"\n",
    "env=gym.make(env_name, render_mode=\"ansi\")\n",
    "\n",
    "#creating the environment to interact with through function \"gym.make\" from the gymnasium model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(341, {'prob': 1.0, 'action_mask': array([1, 1, 0, 1, 0, 0], dtype=int8)})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset(seed=123)\n",
    "\n",
    "#Resetting the environment to its initial state and returning the initial observation\n",
    "#Setting the random seed to 123 makes it so that the envoirponment behaves consistewntly across different systems which allows for uniformity in running the program\n",
    "#Resets the environment env to its initial state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of actions:  6\n",
      "Number of states:  500\n"
     ]
    }
   ],
   "source": [
    "actions=env.action_space.n #retrieving the total number of actions \n",
    "states=env.observation_space.n #retrieving the total number of different observational states\n",
    "print(\"Number of actions: \", actions) #comes out to be 6\n",
    "print(\"Number of states: \", states) #comes out to be 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22460\\2527372943.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0maction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mn_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m     ) -> Optional[Union[RenderFrame, List[RenderFrame]]]:\n\u001b[0;32m    328\u001b[0m         \u001b[1;34m\"\"\"Renders the environment.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                 \u001b[1;34m\"set `disable_render_order_enforcing=True` on the OrderEnforcer wrapper.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m             )\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\wrappers\\env_checker.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0menv_render_passive_checker\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\envs\\toy_text\\taxi.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    286\u001b[0m             )\n\u001b[0;32m    287\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_mode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"ansi\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 288\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    289\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# self.render_mode in {\"human\", \"rgb_array\"}:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_gui\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\gym\\envs\\toy_text\\taxi.py\u001b[0m in \u001b[0;36m_render_text\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_render_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 428\u001b[1;33m         \u001b[0mdesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdesc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    429\u001b[0m         \u001b[0moutfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "episodes=10\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset() if isinstance(env.reset(), int) else env.reset()[0]\n",
    "    done=False #if episode is not completed\n",
    "    score=0 #set score to 0\n",
    "\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action=random.choice([0,1])\n",
    "        n_state, reward, done, truncated, info=env.step(action)\n",
    "        score+=reward #update the scores according to the rewards\n",
    "    print(\"Episode:{} Score:{}\".format(episode,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Embedding, Reshape, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "#importing few more necessary libraries and modules, tensorflow for building and training the neural networks  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "302"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset() #resetting the env \n",
    "env.step(env.action_space.sample())[0] #this code is used to access the first element of the tuple returned by the stap metjod - which is the new state of the environment after the action has been executed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to build the model, only embedding\n",
    "def build_model(states, actions): #\n",
    "    '''model = Sequential()\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))  # Output layer with one value per action\n",
    "    model.compile(optimizer=Adam(lr=0.001), loss='mse')'''\n",
    "    model = Sequential() #making the sequential model\n",
    "    model.add(Embedding(500, 6, input_length=1)) #adding an embedding layer to represent the 500 states with 6 dimensions\n",
    "    model.add(Reshape((6,))) #adding a reshape layer to flatten the output from the embedding layer.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model(states,actions) #rceates a new neural network that we have sccording to the states and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, 1, 6)              3000      \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 6)                 0         \n",
      "=================================================================\n",
      "Total params: 3,000\n",
      "Trainable params: 3,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary() #provides a summary of the neural network model we have created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "#the dqn library helps by implementing the DQN algorithm for learning Q-values\n",
    "#the BoltzmannQPolicy will help by providing a probabilistic action selection strategy based on Q-values, kind of like the epsgreedy strategy\n",
    "#and finally the manages the storage of experiences for training the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym[toy_text] in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.26.2)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from gym[toy_text]) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from gym[toy_text]) (2.2.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from gym[toy_text]) (1.19.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from gym[toy_text]) (6.7.0)\n",
      "Requirement already satisfied: pygame==2.1.0 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from gym[toy_text]) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\kushi arun kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[toy_text]) (3.15.0)\n"
     ]
    }
   ],
   "source": [
    "%pip install gym[toy_text]\n",
    "#I installed this additional dependency as to make sure that there is access to the additional text-based environments provided by Gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dqn_agent(env): #creating and configconfiguring a DQN agent\n",
    "    model = build_model(states, actions) #calling build_model function\n",
    "    policy=BoltzmannQPolicy() #defining the policy \n",
    "    memory=SequentialMemory(limit=50000, window_length=1) #used to store the experiences in terms of state, action, etc; limit is the maximum number of experiences to store in memory; window_length=1 means that each experience consists of a single state-action-reward-next state tuple else there will be multiple states\n",
    "    dqn=DQNAgent(model=model, memory=memory, policy=policy, nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2) \n",
    "\n",
    "    return dqn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = create_dqn_agent(env) #initializing the dqn agent in the environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=0.001), metrics=['mae']) #this line of code sets the DQN agent for training\n",
    "#Adam optimizer is an adaptive learning rate optimization algorithm and we are setting the learning rate to 0.001 here\n",
    "#we are also setting the metrics for mean abosolute error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected embedding_13_input to have 2 dimensions, but got array with shape (1, 1, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22460\\3778130283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\rl\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[1;31m# This is were all of the work happens. We first perceive and compute the action\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;31m# (forward step) and then use the reward to improve (backward step).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                     \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\rl\\agents\\dqn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;31m# Select an action.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_recent_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mq_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\rl\\agents\\dqn.py\u001b[0m in \u001b[0;36mcompute_q_values\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_batch_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\rl\\agents\\dqn.py\u001b[0m in \u001b[0;36mcompute_batch_q_values\u001b[1;34m(self, state_batch)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcompute_batch_q_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_state_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mq_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mq_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m   1198\u001b[0m     \u001b[1;31m# Validate and standardize user data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1199\u001b[0m     inputs, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1200\u001b[1;33m         x, extract_tensors_from_dataset=True)\n\u001b[0m\u001b[0;32m   1201\u001b[0m     \u001b[1;31m# If `self._distribution_strategy` is True, then we are in a replica context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m     \u001b[1;31m# at this point.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2334\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2335\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2336\u001b[1;33m         batch_size=batch_size)\n\u001b[0m\u001b[0;32m   2337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2338\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[1;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[0;32m   2361\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kushi Arun Kumar\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    529\u001b[0m                            \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                            \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                            'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    532\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m           \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected embedding_13_input to have 2 dimensions, but got array with shape (1, 1, 2)"
     ]
    }
   ],
   "source": [
    "dqn.fit(env, nb_steps=5000, visualize=False, verbose=1) #we are training the DQN agent on the specified environment for 5,000 steps, without visualizing the training process\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I faced multiple errors with this method of RL:\n",
    "1. The first being that installing all tensorflow, keras and keras-rl gave an error while importing the libraries, hence I had to uninstall keras and keep keras-rl and tensorflow\n",
    "2. This issue, I was not able to fix, the expected input shape was input data with 2 dimensions but the actual input shape had 3 dimensions with the shape (1, 1, 2), which suggests that it has an extra dimension. Due to this the command for dqn.fit did not work and I could'nt proceed with the same despite trying to solve the issue manier times. \n",
    "\n",
    "Hence this is all I could pull off in the short duration of our submission tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
